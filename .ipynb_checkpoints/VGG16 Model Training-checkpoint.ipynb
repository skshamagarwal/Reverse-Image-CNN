{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pip setuptools wheel\n",
    "# ! pip install pandas \n",
    "# ! pip install numpy tensorflow\n",
    "# ! pip install split-folders\n",
    "# !pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Dataset\n",
    "# import splitfolders\n",
    "# input_dir = \"dataset\"\n",
    "# output_dir = \"data_dir\"\n",
    "\n",
    "# splitfolders.ratio(input_dir, output_dir, seed=1337, ratio=(.6,.4), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"data_dir/train\"\n",
    "valid_dir = \"data_dir/val\"\n",
    "img_width, img_height = 224, 224  # Default input size for VGG16\n",
    "\n",
    "# Instantiate convolutional base\n",
    "model_base = VGG16(weights='imagenet', \n",
    "                  include_top=False,\n",
    "                  input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Show architecture\n",
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 188 images belonging to 6 classes.\n",
      "Found 127 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "# !pip install Pillow\n",
    "\n",
    "import os, shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 7, 7, 512))  # Must be equal to the output of the convolutional base\n",
    "    labels = np.zeros(shape=(sample_count,6))\n",
    "    # Preprocess data\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                            target_size=(img_width,img_height),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode='categorical')\n",
    "    # Pass data through convolutional base\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = model_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "#         print(batch_size, sample_count)\n",
    "    return features, labels\n",
    "    \n",
    "train_features, train_labels = extract_features(train_dir, 188)  # Agree with our small dataset size\n",
    "validation_features, validation_labels = extract_features(valid_dir, 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.05199572, 0.        , 0.        , ..., 0.        ,\n",
       "          0.80576801, 0.        ],\n",
       "         [0.21756813, 0.        , 0.        , ..., 0.        ,\n",
       "          0.75451267, 0.        ],\n",
       "         [0.15857747, 0.        , 0.        , ..., 0.        ,\n",
       "          0.8333236 , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.98360884, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.87681979, 0.        ],\n",
       "         [0.02471793, 0.        , 0.        , ..., 0.        ,\n",
       "          0.90826023, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.86297452, 0.        ],\n",
       "         [0.38768461, 0.        , 0.        , ..., 0.        ,\n",
       "          0.94263875, 0.        ],\n",
       "         [0.81334418, 0.        , 0.84849101, ..., 0.        ,\n",
       "          0.72465813, 0.04855384],\n",
       "         ...,\n",
       "         [0.8392455 , 0.        , 0.82232249, ..., 0.        ,\n",
       "          0.83087409, 0.        ],\n",
       "         [0.39600644, 0.        , 0.96715784, ..., 0.06315212,\n",
       "          0.87519205, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.14200318,\n",
       "          1.09220564, 0.        ]],\n",
       "\n",
       "        [[0.31717893, 0.        , 0.        , ..., 0.        ,\n",
       "          0.75373578, 0.        ],\n",
       "         [0.48415056, 0.        , 0.10928342, ..., 0.        ,\n",
       "          0.89339209, 0.        ],\n",
       "         [0.69584984, 0.        , 0.76746327, ..., 0.        ,\n",
       "          0.64594752, 0.        ],\n",
       "         ...,\n",
       "         [1.04967403, 0.        , 0.38831955, ..., 0.        ,\n",
       "          0.39373198, 0.        ],\n",
       "         [1.19386411, 0.        , 0.75511837, ..., 0.        ,\n",
       "          0.43723801, 0.        ],\n",
       "         [0.41415942, 0.        , 0.        , ..., 0.        ,\n",
       "          0.94798291, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12675847, 0.        , 0.        , ..., 0.        ,\n",
       "          0.77691668, 0.        ],\n",
       "         [0.08239093, 0.        , 0.85010993, ..., 0.        ,\n",
       "          0.92168713, 0.        ],\n",
       "         [0.38075703, 0.        , 1.13963032, ..., 0.        ,\n",
       "          0.29090065, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.80638409, ..., 0.3028276 ,\n",
       "          0.        , 0.        ],\n",
       "         [0.5113548 , 0.        , 0.15571564, ..., 0.        ,\n",
       "          0.33314118, 0.        ],\n",
       "         [0.14636388, 0.        , 0.        , ..., 0.        ,\n",
       "          0.74282146, 0.        ]],\n",
       "\n",
       "        [[0.02757238, 0.        , 0.        , ..., 0.        ,\n",
       "          0.88132811, 0.        ],\n",
       "         [0.11878794, 0.        , 0.44846901, ..., 0.        ,\n",
       "          1.00870192, 0.        ],\n",
       "         [0.58590418, 0.        , 1.01077163, ..., 0.        ,\n",
       "          0.38169274, 0.        ],\n",
       "         ...,\n",
       "         [0.15392786, 0.        , 0.78801727, ..., 0.01027057,\n",
       "          0.        , 0.        ],\n",
       "         [0.34213859, 0.        , 0.36786163, ..., 0.        ,\n",
       "          0.53861862, 0.        ],\n",
       "         [0.13605839, 0.        , 0.        , ..., 0.        ,\n",
       "          0.72292221, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.85538089, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.0412302 , 0.        ],\n",
       "         [0.        , 0.        , 0.39904335, ..., 0.        ,\n",
       "          0.92352372, 0.        ],\n",
       "         ...,\n",
       "         [0.36357638, 0.        , 0.38662636, ..., 0.        ,\n",
       "          0.63060224, 0.        ],\n",
       "         [0.33539787, 0.        , 0.024037  , ..., 0.        ,\n",
       "          0.72934723, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.76304001, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.36931586, 0.        , 0.        , ..., 0.26706457,\n",
       "          0.24647257, 0.        ],\n",
       "         [0.64740682, 0.        , 0.        , ..., 0.        ,\n",
       "          0.3204214 , 0.        ],\n",
       "         [0.72444558, 0.        , 0.        , ..., 0.        ,\n",
       "          0.56529945, 0.        ],\n",
       "         ...,\n",
       "         [0.84699124, 0.        , 0.        , ..., 0.        ,\n",
       "          0.95943445, 0.        ],\n",
       "         [0.8423357 , 0.        , 0.        , ..., 0.        ,\n",
       "          1.18449187, 0.        ],\n",
       "         [0.4979029 , 0.        , 0.        , ..., 0.26719925,\n",
       "          1.19119728, 0.        ]],\n",
       "\n",
       "        [[0.18912438, 0.        , 0.        , ..., 0.        ,\n",
       "          0.50028229, 0.        ],\n",
       "         [0.46011207, 0.        , 0.        , ..., 0.31828403,\n",
       "          0.67152452, 0.        ],\n",
       "         [0.60646296, 0.        , 0.09791905, ..., 0.14850381,\n",
       "          0.61077386, 0.        ],\n",
       "         ...,\n",
       "         [1.21376014, 0.        , 0.13643867, ..., 0.        ,\n",
       "          0.63176781, 0.        ],\n",
       "         [1.24796581, 0.        , 0.02685428, ..., 0.        ,\n",
       "          1.5924499 , 0.        ],\n",
       "         [0.78347427, 0.        , 0.17238146, ..., 0.        ,\n",
       "          1.52322841, 0.        ]],\n",
       "\n",
       "        [[0.19852313, 0.        , 0.        , ..., 0.        ,\n",
       "          0.8298192 , 0.        ],\n",
       "         [0.19189467, 0.        , 0.99551761, ..., 0.44697049,\n",
       "          0.9262358 , 0.        ],\n",
       "         [0.        , 0.        , 1.43685961, ..., 0.39387542,\n",
       "          0.67948431, 0.        ],\n",
       "         ...,\n",
       "         [1.08934927, 0.        , 0.52857012, ..., 0.        ,\n",
       "          0.1784724 , 0.        ],\n",
       "         [1.54814959, 0.        , 0.        , ..., 0.        ,\n",
       "          0.82504278, 0.        ],\n",
       "         [1.05451465, 0.        , 0.16968659, ..., 0.        ,\n",
       "          1.14386368, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.21163298, 0.        , 0.        , ..., 0.        ,\n",
       "          0.774544  , 0.        ],\n",
       "         [0.18977076, 0.        , 0.80961502, ..., 0.        ,\n",
       "          1.23519111, 0.        ],\n",
       "         [0.        , 0.        , 0.58414006, ..., 0.        ,\n",
       "          1.27824068, 0.        ],\n",
       "         ...,\n",
       "         [0.02178857, 0.        , 1.07761061, ..., 0.        ,\n",
       "          0.56740701, 0.        ],\n",
       "         [0.        , 0.        , 0.50940371, ..., 0.        ,\n",
       "          0.78819966, 0.        ],\n",
       "         [0.02321532, 0.        , 0.        , ..., 0.        ,\n",
       "          0.77740741, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.67153919, 0.        ],\n",
       "         [0.10358202, 0.        , 0.        , ..., 0.        ,\n",
       "          1.20999169, 0.        ],\n",
       "         [0.35859406, 0.        , 0.        , ..., 0.        ,\n",
       "          1.28577757, 0.        ],\n",
       "         ...,\n",
       "         [0.64604533, 0.        , 0.75766307, ..., 0.        ,\n",
       "          1.09029281, 0.        ],\n",
       "         [1.01903701, 0.        , 0.8026098 , ..., 0.        ,\n",
       "          1.22626805, 0.        ],\n",
       "         [0.56323445, 0.        , 0.        , ..., 0.        ,\n",
       "          0.84756601, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.88689744, 0.        ],\n",
       "         [0.09226195, 0.        , 0.20970476, ..., 0.        ,\n",
       "          0.78923869, 0.        ],\n",
       "         [0.39699852, 0.        , 0.21175057, ..., 0.        ,\n",
       "          0.91506588, 0.        ],\n",
       "         ...,\n",
       "         [0.22759272, 0.        , 0.09801346, ..., 0.        ,\n",
       "          1.03986764, 0.        ],\n",
       "         [0.58788443, 0.        , 0.3333644 , ..., 0.        ,\n",
       "          0.89227462, 0.        ],\n",
       "         [0.55577493, 0.        , 0.11634019, ..., 0.        ,\n",
       "          0.88450956, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.06266344, 0.        , 0.        , ..., 0.        ,\n",
       "          0.59231144, 0.        ],\n",
       "         [0.15459701, 0.        , 0.        , ..., 0.        ,\n",
       "          0.69209027, 0.        ],\n",
       "         [0.1055509 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.72503078, 0.        ],\n",
       "         ...,\n",
       "         [0.09276268, 0.        , 0.38354659, ..., 0.        ,\n",
       "          0.56595314, 0.        ],\n",
       "         [0.10693206, 0.        , 0.25525936, ..., 0.        ,\n",
       "          0.72567815, 0.        ],\n",
       "         [0.1075128 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.76088238, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.49920189, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.55942667, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.53363448, 0.        ],\n",
       "         ...,\n",
       "         [0.04715864, 0.24256885, 1.5462811 , ..., 0.        ,\n",
       "          0.20682222, 0.        ],\n",
       "         [0.77781099, 0.09178847, 0.90678507, ..., 0.        ,\n",
       "          0.80521268, 0.        ],\n",
       "         [0.78351384, 0.        , 0.        , ..., 0.        ,\n",
       "          0.78899121, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.52522588, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.59595871, 0.        ],\n",
       "         [0.        , 0.        , 0.06025341, ..., 0.        ,\n",
       "          0.40856352, 0.        ],\n",
       "         ...,\n",
       "         [0.47261429, 0.35434777, 1.61556864, ..., 0.        ,\n",
       "          0.01058382, 0.        ],\n",
       "         [1.24247062, 0.        , 0.45441997, ..., 0.        ,\n",
       "          0.82251495, 0.        ],\n",
       "         [1.05312037, 0.        , 0.        , ..., 0.        ,\n",
       "          0.94651544, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01810583, 0.        , 0.        , ..., 0.        ,\n",
       "          0.34540164, 0.        ],\n",
       "         [0.79811674, 0.        , 0.        , ..., 0.        ,\n",
       "          0.33849385, 0.        ],\n",
       "         [0.2388328 , 0.        , 0.4308092 , ..., 0.14796881,\n",
       "          0.90303862, 0.        ],\n",
       "         ...,\n",
       "         [1.00342119, 0.        , 0.76009554, ..., 0.        ,\n",
       "          1.10970068, 0.        ],\n",
       "         [0.18604958, 0.        , 2.73181081, ..., 0.        ,\n",
       "          0.24542508, 0.        ],\n",
       "         [0.23529473, 0.        , 1.73704982, ..., 0.        ,\n",
       "          0.63702124, 0.        ]],\n",
       "\n",
       "        [[1.09467959, 0.        , 0.63153821, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [1.35794699, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.61210489, 0.        , 0.        , ..., 0.        ,\n",
       "          0.74718308, 0.        ],\n",
       "         ...,\n",
       "         [0.91925883, 0.        , 1.61194611, ..., 0.36114466,\n",
       "          1.00341964, 0.        ],\n",
       "         [1.6753068 , 0.        , 3.16358638, ..., 0.92801225,\n",
       "          0.        , 0.        ],\n",
       "         [0.9405269 , 0.        , 2.12435532, ..., 0.56582594,\n",
       "          0.87341678, 0.        ]],\n",
       "\n",
       "        [[1.03169012, 0.        , 0.23438933, ..., 0.        ,\n",
       "          0.36160713, 0.        ],\n",
       "         [1.20825243, 0.        , 0.        , ..., 0.        ,\n",
       "          0.49388963, 0.        ],\n",
       "         [0.59046888, 0.        , 0.06401682, ..., 0.02582163,\n",
       "          0.69479215, 0.        ],\n",
       "         ...,\n",
       "         [0.66353852, 0.        , 0.52154005, ..., 0.        ,\n",
       "          0.38953578, 0.        ],\n",
       "         [1.3345226 , 0.        , 1.07994175, ..., 0.40473154,\n",
       "          0.6075272 , 0.        ],\n",
       "         [0.92642999, 0.        , 0.86446708, ..., 0.        ,\n",
       "          0.96073472, 0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.24888699, 0.        , 0.        , ..., 0.        ,\n",
       "          0.77308238, 0.        ],\n",
       "         [0.        , 0.        , 0.16004848, ..., 0.        ,\n",
       "          0.47869936, 0.        ],\n",
       "         [0.04878628, 0.        , 0.        , ..., 0.        ,\n",
       "          0.63607836, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.70545828, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.71129829, 0.        ],\n",
       "         [0.13697344, 0.        , 0.        , ..., 0.        ,\n",
       "          0.7716018 , 0.        ]],\n",
       "\n",
       "        [[0.32798463, 0.        , 0.        , ..., 0.        ,\n",
       "          0.23580611, 0.        ],\n",
       "         [0.        , 0.        , 0.47922921, ..., 0.00747786,\n",
       "          0.        , 0.        ],\n",
       "         [0.02388427, 0.07917219, 0.47154069, ..., 0.08493522,\n",
       "          0.65839416, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.0423528 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.72332168, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.64265144, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.058815  , ..., 0.        ,\n",
       "          0.02608562, 0.        ],\n",
       "         [0.06384882, 0.        , 2.06494045, ..., 0.10723223,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.16662794, 2.02313089, ..., 1.26043308,\n",
       "          0.96543217, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.37392187, ..., 0.83321154,\n",
       "          1.15439153, 0.        ],\n",
       "         [0.        , 0.        , 0.60525274, ..., 0.29560864,\n",
       "          0.82266021, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.50690877, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 2.35808516, ..., 0.80241328,\n",
       "          0.16955876, 0.        ],\n",
       "         [0.75966197, 0.        , 0.19546327, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.9736439 , 0.56134754, 0.        , ..., 0.00833475,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [2.40325451, 0.        , 0.41641691, ..., 0.65133035,\n",
       "          1.27358723, 0.        ],\n",
       "         [0.75762451, 0.        , 0.89730823, ..., 0.43281141,\n",
       "          1.19524741, 0.        ],\n",
       "         [0.        , 0.        , 0.12182069, ..., 0.        ,\n",
       "          0.55419391, 0.        ]],\n",
       "\n",
       "        [[0.75447148, 0.        , 0.91616225, ..., 0.        ,\n",
       "          0.26798227, 0.        ],\n",
       "         [0.21017593, 0.42530972, 0.        , ..., 0.        ,\n",
       "          0.157646  , 0.        ],\n",
       "         [0.        , 1.03334641, 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [1.46557045, 0.        , 0.09429696, ..., 0.        ,\n",
       "          0.19402584, 0.        ],\n",
       "         [0.        , 0.        , 0.56667507, ..., 0.        ,\n",
       "          0.34706834, 0.        ],\n",
       "         [0.15916368, 0.        , 0.        , ..., 0.        ,\n",
       "          0.52036953, 0.        ]],\n",
       "\n",
       "        [[0.46511441, 0.        , 0.        , ..., 0.        ,\n",
       "          0.59414327, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.65167391, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.77485096, 0.        ],\n",
       "         [0.        , 0.        , 0.21369362, ..., 0.        ,\n",
       "          0.01801062, 0.        ],\n",
       "         [0.12147254, 0.        , 0.        , ..., 0.        ,\n",
       "          0.53587306, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.86029923, 0.        , 0.18873137, ..., 0.        ,\n",
       "          0.88416457, 0.        ],\n",
       "         [1.05222321, 0.        , 0.        , ..., 0.        ,\n",
       "          0.97249228, 0.        ],\n",
       "         [0.13714644, 0.        , 0.        , ..., 0.        ,\n",
       "          0.53208971, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.53180999, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.7571457 , 0.        ],\n",
       "         [0.10021309, 0.        , 0.        , ..., 0.        ,\n",
       "          0.76252276, 0.        ]],\n",
       "\n",
       "        [[2.38677597, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [1.87126875, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.1517038 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.45241654, 0.        ],\n",
       "         ...,\n",
       "         [0.11836643, 0.        , 0.        , ..., 0.        ,\n",
       "          0.49585867, 0.        ],\n",
       "         [0.45845467, 0.        , 0.        , ..., 0.        ,\n",
       "          0.67577308, 0.        ],\n",
       "         [0.63194072, 0.        , 0.        , ..., 0.        ,\n",
       "          0.65653378, 0.        ]],\n",
       "\n",
       "        [[2.29332328, 0.        , 0.        , ..., 0.46620235,\n",
       "          0.06676841, 0.        ],\n",
       "         [1.59126508, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.18667473, 0.        , 0.14567044, ..., 0.        ,\n",
       "          0.58483034, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.63066149, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.46381038, 0.        ],\n",
       "         [0.        , 0.        , 0.09182814, ..., 0.        ,\n",
       "          0.04407358, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.30448794, 0.        , 0.14383495, ..., 0.        ,\n",
       "          0.86337119, 0.        ],\n",
       "         [1.06852674, 0.        , 0.3532775 , ..., 0.        ,\n",
       "          1.09320176, 0.        ],\n",
       "         [0.        , 0.        , 0.09420592, ..., 0.        ,\n",
       "          1.3937    , 0.        ],\n",
       "         ...,\n",
       "         [0.41794759, 0.        , 0.10546476, ..., 0.19448587,\n",
       "          1.65961075, 0.        ],\n",
       "         [0.63641882, 0.        , 0.        , ..., 0.43879139,\n",
       "          1.59765482, 0.        ],\n",
       "         [0.48355219, 0.        , 0.        , ..., 0.        ,\n",
       "          1.12420583, 0.        ]],\n",
       "\n",
       "        [[1.31814957, 0.        , 0.13339224, ..., 0.        ,\n",
       "          0.96060896, 0.        ],\n",
       "         [1.30600905, 0.        , 0.38711756, ..., 0.30274689,\n",
       "          0.90515745, 0.        ],\n",
       "         [0.15267381, 0.        , 0.07471585, ..., 0.44520953,\n",
       "          1.36549997, 0.        ],\n",
       "         ...,\n",
       "         [1.45731032, 0.        , 0.08203354, ..., 0.        ,\n",
       "          0.76092744, 0.        ],\n",
       "         [2.44128036, 0.        , 0.        , ..., 0.        ,\n",
       "          0.91444111, 0.        ],\n",
       "         [2.19751263, 0.        , 0.        , ..., 0.        ,\n",
       "          1.09157348, 0.        ]],\n",
       "\n",
       "        [[0.21390431, 0.        , 0.06557363, ..., 0.        ,\n",
       "          0.71981275, 0.        ],\n",
       "         [0.28446588, 0.        , 0.0149278 , ..., 0.06648026,\n",
       "          0.77896738, 0.        ],\n",
       "         [0.24058349, 0.        , 0.        , ..., 0.08394021,\n",
       "          0.91248471, 0.        ],\n",
       "         ...,\n",
       "         [1.18585491, 0.        , 0.30085808, ..., 0.        ,\n",
       "          0.63180602, 0.        ],\n",
       "         [2.43718195, 0.        , 0.        , ..., 0.        ,\n",
       "          0.59979141, 0.        ],\n",
       "         [2.28442001, 0.        , 0.        , ..., 0.        ,\n",
       "          0.76378834, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.82284003, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.88309586, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.98825943, 0.        ],\n",
       "         ...,\n",
       "         [0.2820251 , 0.        , 0.        , ..., 0.42586488,\n",
       "          0.80349708, 0.        ],\n",
       "         [0.38249519, 0.        , 0.        , ..., 0.48399311,\n",
       "          0.94023967, 0.        ],\n",
       "         [0.23505989, 0.        , 0.        , ..., 0.11958703,\n",
       "          0.97669214, 0.        ]],\n",
       "\n",
       "        [[0.45434836, 0.        , 0.        , ..., 0.        ,\n",
       "          0.68423057, 0.        ],\n",
       "         [0.50244814, 0.        , 0.        , ..., 0.        ,\n",
       "          0.64874393, 0.        ],\n",
       "         [0.54077697, 0.        , 0.        , ..., 0.        ,\n",
       "          0.80949724, 0.        ],\n",
       "         ...,\n",
       "         [0.59894133, 0.        , 0.        , ..., 0.48462662,\n",
       "          0.93648195, 0.        ],\n",
       "         [0.79853052, 0.        , 0.        , ..., 0.38389757,\n",
       "          0.95008874, 0.        ],\n",
       "         [0.27385461, 0.        , 0.        , ..., 0.06848376,\n",
       "          1.00789928, 0.        ]],\n",
       "\n",
       "        [[0.2318047 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.68976045, 0.        ],\n",
       "         [0.54054725, 0.        , 0.41549748, ..., 0.        ,\n",
       "          0.49042875, 0.        ],\n",
       "         [0.63984442, 0.        , 0.40302682, ..., 0.        ,\n",
       "          0.43804651, 0.        ],\n",
       "         ...,\n",
       "         [0.34732416, 0.        , 0.        , ..., 0.        ,\n",
       "          1.14506841, 0.        ],\n",
       "         [0.44023824, 0.        , 0.        , ..., 0.        ,\n",
       "          1.03150129, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.7741251 , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.65506929, 0.        ],\n",
       "         [0.06548856, 0.        , 0.        , ..., 0.40424675,\n",
       "          0.65861946, 0.        ],\n",
       "         [0.        , 0.39993632, 0.        , ..., 0.62439144,\n",
       "          0.80567676, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.21394891, ..., 0.        ,\n",
       "          0.7925418 , 0.        ],\n",
       "         [0.13866776, 0.        , 0.86783391, ..., 0.        ,\n",
       "          0.90583551, 0.        ],\n",
       "         [0.21525343, 0.        , 1.17799044, ..., 0.        ,\n",
       "          0.70793194, 0.        ]],\n",
       "\n",
       "        [[0.29834002, 0.        , 0.        , ..., 0.        ,\n",
       "          0.71904802, 0.        ],\n",
       "         [0.31202868, 0.        , 0.        , ..., 0.        ,\n",
       "          0.64622378, 0.        ],\n",
       "         [0.09036049, 0.        , 0.        , ..., 0.        ,\n",
       "          0.21201119, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.82856309, ..., 0.        ,\n",
       "          0.70336044, 0.        ],\n",
       "         [0.04370856, 0.        , 1.61126089, ..., 0.        ,\n",
       "          0.78320378, 0.        ],\n",
       "         [0.42172733, 0.        , 1.45393491, ..., 0.16630402,\n",
       "          0.78876579, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.71756101, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.89055955, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.89958799, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 1.13398731, ..., 0.        ,\n",
       "          1.0632    , 0.        ],\n",
       "         [0.04657348, 0.        , 1.43975377, ..., 0.        ,\n",
       "          1.1724242 , 0.        ],\n",
       "         [0.26458085, 0.        , 0.75646585, ..., 0.18861389,\n",
       "          0.96016252, 0.        ]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.85539651, 0.        ],\n",
       "         [0.        , 0.        , 1.46056604, ..., 0.        ,\n",
       "          0.45805979, 0.        ],\n",
       "         [0.        , 0.        , 1.0033716 , ..., 0.        ,\n",
       "          0.68843108, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.3507174 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.5558064 , 0.        ],\n",
       "         [0.00887898, 0.        , 0.        , ..., 0.        ,\n",
       "          0.58645761, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.43088013, ..., 0.        ,\n",
       "          0.47154975, 0.        ],\n",
       "         [0.06014371, 0.        , 1.75774336, ..., 0.22077808,\n",
       "          0.01950032, 0.        ],\n",
       "         [0.        , 0.        , 0.91193509, ..., 0.80950481,\n",
       "          0.4920426 , 0.        ],\n",
       "         ...,\n",
       "         [0.01980078, 0.        , 0.30976391, ..., 0.        ,\n",
       "          0.53132653, 0.        ],\n",
       "         [0.18311192, 0.        , 0.0374189 , ..., 0.        ,\n",
       "          0.91250634, 0.        ],\n",
       "         [0.1137894 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.7582916 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.60382235, 0.        ],\n",
       "         [0.        , 0.        , 0.18875521, ..., 0.        ,\n",
       "          0.25743517, 0.        ],\n",
       "         [0.        , 0.        , 0.39990923, ..., 0.88084501,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [1.36558223, 0.        , 0.0606162 , ..., 0.66549081,\n",
       "          1.06573641, 0.        ],\n",
       "         [0.40750515, 0.        , 0.        , ..., 0.56673795,\n",
       "          0.94951534, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.16375904,\n",
       "          0.83623791, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.55834085, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.22428137, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.49251521, 0.        ],\n",
       "         ...,\n",
       "         [1.65125513, 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [1.16160643, 0.        , 0.        , ..., 0.        ,\n",
       "          0.12805372, 0.        ],\n",
       "         [0.90148956, 0.        , 0.        , ..., 0.00861859,\n",
       "          0.4501099 , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.82086492, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.78502762, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.02038365,\n",
       "          0.78860301, 0.        ],\n",
       "         ...,\n",
       "         [0.65971172, 0.        , 0.        , ..., 0.19604592,\n",
       "          0.04541582, 0.        ],\n",
       "         [0.61299694, 0.        , 0.        , ..., 0.        ,\n",
       "          0.62430233, 0.        ],\n",
       "         [0.46000212, 0.        , 0.        , ..., 0.        ,\n",
       "          0.73355293, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.04728074,\n",
       "          0.90379739, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.77366048, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.79442436, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.18645382,\n",
       "          0.74622452, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.71916747, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.61976182, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.25582474, 0.        , 1.05190897, ..., 0.        ,\n",
       "          0.72601265, 0.        ],\n",
       "         [0.1128132 , 0.        , 0.76843542, ..., 0.        ,\n",
       "          0.76458621, 0.        ],\n",
       "         [0.        , 0.        , 0.41194972, ..., 0.        ,\n",
       "          0.75543427, 0.        ],\n",
       "         ...,\n",
       "         [0.84555978, 0.        , 0.65529299, ..., 0.        ,\n",
       "          0.68719375, 0.        ],\n",
       "         [0.59817183, 0.        , 0.36254764, ..., 0.        ,\n",
       "          1.34674931, 0.        ],\n",
       "         [0.15488233, 0.        , 0.        , ..., 0.02201353,\n",
       "          1.40179944, 0.        ]],\n",
       "\n",
       "        [[0.15557155, 0.        , 0.67450035, ..., 0.        ,\n",
       "          0.84804308, 0.        ],\n",
       "         [0.        , 0.        , 1.1393137 , ..., 0.        ,\n",
       "          0.78261942, 0.        ],\n",
       "         [0.31883773, 0.        , 1.18924212, ..., 0.        ,\n",
       "          0.73740911, 0.        ],\n",
       "         ...,\n",
       "         [1.74311256, 0.        , 1.1900388 , ..., 0.        ,\n",
       "          0.24358222, 0.        ],\n",
       "         [1.8504703 , 0.        , 0.98201084, ..., 0.        ,\n",
       "          1.41397691, 0.        ],\n",
       "         [1.64900219, 0.        , 0.        , ..., 0.00967363,\n",
       "          1.64233589, 0.        ]],\n",
       "\n",
       "        [[0.24558817, 0.        , 0.58997548, ..., 0.        ,\n",
       "          1.03664768, 0.        ],\n",
       "         [0.44279173, 0.        , 1.99375987, ..., 0.        ,\n",
       "          0.91951603, 0.        ],\n",
       "         [0.18265451, 0.        , 1.69868088, ..., 0.        ,\n",
       "          0.88010663, 0.        ],\n",
       "         ...,\n",
       "         [1.64793861, 0.        , 0.59011298, ..., 0.        ,\n",
       "          0.14980844, 0.        ],\n",
       "         [2.09706163, 0.        , 0.47944412, ..., 0.        ,\n",
       "          1.10503042, 0.        ],\n",
       "         [2.37828112, 0.        , 0.31967968, ..., 0.        ,\n",
       "          0.86331558, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58881921, 0.        , 0.24506408, ..., 0.        ,\n",
       "          0.55099678, 0.        ],\n",
       "         [1.2156533 , 0.        , 0.79249197, ..., 0.        ,\n",
       "          0.24042606, 0.        ],\n",
       "         [1.33236361, 0.        , 1.22518313, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [1.37187409, 0.        , 0.96341419, ..., 0.        ,\n",
       "          0.19629085, 0.        ],\n",
       "         [2.39143586, 0.        , 1.11305809, ..., 0.        ,\n",
       "          0.64923227, 0.        ],\n",
       "         [2.47339058, 0.        , 0.40074667, ..., 0.        ,\n",
       "          0.81188989, 0.        ]],\n",
       "\n",
       "        [[0.64667118, 0.        , 0.62266219, ..., 0.        ,\n",
       "          0.95027876, 0.        ],\n",
       "         [0.23161033, 0.        , 0.37100422, ..., 0.        ,\n",
       "          0.2320593 , 0.        ],\n",
       "         [0.        , 0.        , 0.74852407, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [1.05908108, 0.        , 0.72920144, ..., 0.        ,\n",
       "          0.71995962, 0.        ],\n",
       "         [0.98926586, 0.        , 0.58771133, ..., 0.        ,\n",
       "          0.67438531, 0.        ],\n",
       "         [0.16481256, 0.        , 0.28850555, ..., 0.        ,\n",
       "          0.27915293, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.98125458, ..., 0.        ,\n",
       "          0.96605742, 0.        ],\n",
       "         [0.        , 0.        , 0.18471149, ..., 0.        ,\n",
       "          0.42545018, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.05360454, 0.        ],\n",
       "         ...,\n",
       "         [0.29765293, 0.        , 0.        , ..., 0.        ,\n",
       "          0.89548701, 0.        ],\n",
       "         [0.33888936, 0.        , 0.12893873, ..., 0.        ,\n",
       "          0.86545229, 0.        ],\n",
       "         [0.55044258, 0.        , 0.67709023, ..., 0.        ,\n",
       "          0.09792191, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.25702596, ..., 0.        ,\n",
       "          0.49126461, 0.        ],\n",
       "         [0.3448332 , 0.        , 0.45426157, ..., 0.        ,\n",
       "          0.6837464 , 0.        ],\n",
       "         [0.31092745, 0.        , 0.        , ..., 0.        ,\n",
       "          0.70060807, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.24594364, ..., 0.31021243,\n",
       "          0.80238611, 0.        ],\n",
       "         [0.04682162, 0.        , 0.57386065, ..., 0.12066744,\n",
       "          1.00774205, 0.        ],\n",
       "         [0.        , 0.        , 0.37358564, ..., 0.        ,\n",
       "          0.61452752, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 1.36602557, ..., 0.        ,\n",
       "          0.64946187, 0.        ],\n",
       "         [0.        , 0.        , 0.90774208, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.57838154, 0.        , 1.14781046, ..., 0.        ,\n",
       "          0.27708328, 0.        ],\n",
       "         ...,\n",
       "         [0.07434244, 0.        , 0.64625323, ..., 0.        ,\n",
       "          0.70938373, 0.        ],\n",
       "         [0.16716641, 0.        , 0.39770037, ..., 0.        ,\n",
       "          0.97717774, 0.        ],\n",
       "         [0.09260178, 0.        , 0.59223688, ..., 0.        ,\n",
       "          0.60920781, 0.        ]],\n",
       "\n",
       "        [[0.2932016 , 0.        , 0.95274037, ..., 0.        ,\n",
       "          1.29001951, 0.        ],\n",
       "         [0.07679714, 0.        , 0.78206336, ..., 0.        ,\n",
       "          0.09622687, 0.        ],\n",
       "         [0.14117192, 0.        , 1.03073585, ..., 0.        ,\n",
       "          0.12775344, 0.        ],\n",
       "         ...,\n",
       "         [0.30566663, 0.        , 0.70701468, ..., 0.        ,\n",
       "          0.5822655 , 0.        ],\n",
       "         [0.10641457, 0.        , 0.65170908, ..., 0.        ,\n",
       "          0.61299556, 0.        ],\n",
       "         [0.25335172, 0.        , 0.18407062, ..., 0.        ,\n",
       "          0.27066371, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.36210483, ..., 0.        ,\n",
       "          1.14303553, 0.        ],\n",
       "         [0.13745677, 0.        , 0.0330531 , ..., 0.        ,\n",
       "          1.20940518, 0.        ],\n",
       "         [0.        , 0.        , 0.0969992 , ..., 0.        ,\n",
       "          1.29151797, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.41193971, ..., 0.        ,\n",
       "          0.75939846, 0.        ],\n",
       "         [0.        , 0.        , 0.81200802, ..., 0.        ,\n",
       "          0.84738421, 0.        ],\n",
       "         [0.68849176, 0.        , 0.77581602, ..., 0.        ,\n",
       "          0.77087867, 0.        ]],\n",
       "\n",
       "        [[0.1787996 , 0.        , 0.10133871, ..., 0.        ,\n",
       "          1.299932  , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.53539991, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.70723224, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.00901932, ..., 0.        ,\n",
       "          1.14798212, 0.        ],\n",
       "         [0.46908665, 0.        , 0.44055679, ..., 0.        ,\n",
       "          1.3452493 , 0.        ],\n",
       "         [0.60938656, 0.        , 0.50460869, ..., 0.        ,\n",
       "          0.98166984, 0.        ]],\n",
       "\n",
       "        [[0.05296943, 0.        , 0.42212304, ..., 0.38419235,\n",
       "          0.99846494, 0.        ],\n",
       "         [0.        , 0.        , 0.02782917, ..., 0.41998667,\n",
       "          1.32295156, 0.        ],\n",
       "         [0.        , 0.        , 0.02314758, ..., 0.        ,\n",
       "          1.54770565, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.08965957, 0.        ],\n",
       "         [0.19095443, 0.        , 0.        , ..., 0.        ,\n",
       "          1.25388241, 0.        ],\n",
       "         [0.33464456, 0.        , 0.        , ..., 0.        ,\n",
       "          1.02049851, 0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.28943041, ..., 0.        ,\n",
       "          0.96766698, 0.        ],\n",
       "         [0.22037643, 0.        , 0.78245199, ..., 0.        ,\n",
       "          0.53337765, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.15956682, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.22035891, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 1.09214914, ..., 0.        ,\n",
       "          0.2995666 , 0.        ]],\n",
       "\n",
       "        [[0.47789711, 0.        , 2.05491471, ..., 0.        ,\n",
       "          1.04740739, 0.        ],\n",
       "         [0.23239201, 0.        , 2.43989754, ..., 0.        ,\n",
       "          0.43511635, 0.        ],\n",
       "         [0.09785526, 0.        , 1.37641704, ..., 0.        ,\n",
       "          0.14791363, 0.        ],\n",
       "         ...,\n",
       "         [0.76504791, 0.        , 1.06745863, ..., 0.        ,\n",
       "          0.90656489, 0.        ],\n",
       "         [0.46647587, 0.        , 0.23668143, ..., 0.        ,\n",
       "          0.77149433, 0.        ],\n",
       "         [0.23927747, 0.        , 1.00823641, ..., 0.        ,\n",
       "          0.61648369, 0.        ]],\n",
       "\n",
       "        [[0.91391701, 0.        , 2.20725393, ..., 0.        ,\n",
       "          0.36757535, 0.        ],\n",
       "         [0.45362335, 0.        , 2.799402  , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.14544733, 0.        , 2.28836203, ..., 0.27857381,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [2.45853233, 0.        , 0.80826986, ..., 0.21755943,\n",
       "          0.82218575, 0.        ],\n",
       "         [2.04544139, 0.        , 0.43631381, ..., 0.        ,\n",
       "          0.73006827, 0.        ],\n",
       "         [0.96530837, 0.        , 0.56630993, ..., 0.        ,\n",
       "          0.6974737 , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.94484365, 0.        ],\n",
       "         [0.69124216, 0.        , 0.16537514, ..., 0.        ,\n",
       "          0.71875018, 0.        ],\n",
       "         [0.63600093, 0.        , 0.        , ..., 0.        ,\n",
       "          0.50156236, 0.        ],\n",
       "         ...,\n",
       "         [1.44712257, 0.        , 1.14578593, ..., 0.        ,\n",
       "          0.15770599, 0.        ],\n",
       "         [1.8342278 , 0.        , 0.78724873, ..., 0.        ,\n",
       "          0.62051344, 0.        ],\n",
       "         [0.84375668, 0.        , 0.        , ..., 0.        ,\n",
       "          0.72881836, 0.        ]],\n",
       "\n",
       "        [[0.3833473 , 0.        , 0.        , ..., 0.        ,\n",
       "          0.93310004, 0.        ],\n",
       "         [0.57021201, 0.        , 0.        , ..., 0.        ,\n",
       "          0.78088784, 0.        ],\n",
       "         [0.92117995, 0.        , 0.        , ..., 0.        ,\n",
       "          0.36036238, 0.        ],\n",
       "         ...,\n",
       "         [1.42349029, 0.        , 1.10750139, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [1.51284552, 0.        , 0.89554805, ..., 0.        ,\n",
       "          0.33499229, 0.        ],\n",
       "         [1.31053793, 0.        , 0.        , ..., 0.        ,\n",
       "          0.57589936, 0.        ]],\n",
       "\n",
       "        [[0.40129334, 0.        , 0.        , ..., 0.        ,\n",
       "          0.70456636, 0.        ],\n",
       "         [0.42400604, 0.        , 0.        , ..., 0.        ,\n",
       "          0.54944569, 0.        ],\n",
       "         [0.63028365, 0.        , 0.        , ..., 0.        ,\n",
       "          0.45106256, 0.        ],\n",
       "         ...,\n",
       "         [0.64550298, 0.        , 0.3607035 , ..., 0.        ,\n",
       "          0.37466705, 0.        ],\n",
       "         [0.71569675, 0.        , 0.41917422, ..., 0.        ,\n",
       "          0.73594618, 0.        ],\n",
       "         [0.89914924, 0.        , 0.        , ..., 0.        ,\n",
       "          0.78654838, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.42003587, 0.        , 0.        , ..., 0.        ,\n",
       "          0.71178806, 0.        ],\n",
       "         [0.18945232, 0.        , 0.65164107, ..., 0.        ,\n",
       "          0.79620153, 0.        ],\n",
       "         [1.04235303, 0.        , 1.64039731, ..., 0.        ,\n",
       "          0.59115714, 0.        ],\n",
       "         ...,\n",
       "         [0.86040211, 0.        , 1.43877637, ..., 0.        ,\n",
       "          0.46250039, 0.        ],\n",
       "         [0.14534996, 0.        , 1.1286397 , ..., 0.        ,\n",
       "          0.82340497, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.89016587, 0.        ]],\n",
       "\n",
       "        [[0.52567518, 0.        , 0.        , ..., 0.        ,\n",
       "          0.90552449, 0.        ],\n",
       "         [0.62590325, 0.        , 0.89005411, ..., 0.        ,\n",
       "          0.75174332, 0.        ],\n",
       "         [1.63854611, 0.        , 1.85409069, ..., 0.        ,\n",
       "          0.34974891, 0.35540679],\n",
       "         ...,\n",
       "         [1.04402721, 0.        , 1.49673891, ..., 0.02683339,\n",
       "          0.41017362, 0.        ],\n",
       "         [1.51539612, 0.        , 1.53079319, ..., 0.        ,\n",
       "          0.7563287 , 0.        ],\n",
       "         [0.87374097, 0.        , 0.78492898, ..., 0.        ,\n",
       "          0.84318346, 0.        ]],\n",
       "\n",
       "        [[0.18929218, 0.        , 0.18843302, ..., 0.        ,\n",
       "          1.00947523, 0.        ],\n",
       "         [0.55959523, 0.        , 0.22046131, ..., 0.        ,\n",
       "          0.77799809, 0.        ],\n",
       "         [0.84911972, 0.        , 0.42870438, ..., 0.        ,\n",
       "          0.60107404, 0.        ],\n",
       "         ...,\n",
       "         [1.14450717, 0.        , 0.68395865, ..., 0.        ,\n",
       "          0.5612815 , 0.        ],\n",
       "         [1.7154088 , 0.        , 0.62586379, ..., 0.        ,\n",
       "          0.73508114, 0.        ],\n",
       "         [1.26789844, 0.        , 0.49456951, ..., 0.        ,\n",
       "          0.93695128, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.66712666, ..., 0.        ,\n",
       "          0.86653578, 0.        ],\n",
       "         [0.29946744, 0.        , 0.45653909, ..., 0.        ,\n",
       "          0.66414225, 0.        ],\n",
       "         [1.16399789, 0.        , 0.30333635, ..., 0.        ,\n",
       "          0.54593378, 0.        ],\n",
       "         ...,\n",
       "         [0.57177335, 0.        , 0.47706246, ..., 0.        ,\n",
       "          0.49845809, 0.        ],\n",
       "         [0.55020732, 0.        , 0.        , ..., 0.        ,\n",
       "          0.56427705, 0.        ],\n",
       "         [0.12309909, 0.        , 0.        , ..., 0.        ,\n",
       "          0.74688947, 0.        ]],\n",
       "\n",
       "        [[0.06233287, 0.        , 0.28917485, ..., 0.        ,\n",
       "          0.92369986, 0.        ],\n",
       "         [0.78607196, 0.        , 0.        , ..., 0.        ,\n",
       "          0.5654617 , 0.        ],\n",
       "         [1.04840493, 0.        , 0.28782213, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.68839645, 0.        , 0.58356965, ..., 0.        ,\n",
       "          0.28812116, 0.        ],\n",
       "         [0.53502232, 0.        , 0.47564891, ..., 0.        ,\n",
       "          0.5552448 , 0.        ],\n",
       "         [0.37125945, 0.        , 0.12635475, ..., 0.        ,\n",
       "          1.00671625, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.69815493, 0.        ],\n",
       "         [1.05633879, 0.        , 0.05417141, ..., 0.        ,\n",
       "          0.47695646, 0.        ],\n",
       "         [1.08316028, 0.        , 0.04410332, ..., 0.        ,\n",
       "          0.24427718, 0.        ],\n",
       "         ...,\n",
       "         [0.38529912, 0.        , 0.99450392, ..., 0.        ,\n",
       "          0.32112893, 0.        ],\n",
       "         [0.11816804, 0.        , 0.74867737, ..., 0.        ,\n",
       "          0.24300396, 0.        ],\n",
       "         [0.0606387 , 0.        , 0.60886872, ..., 0.        ,\n",
       "          0.8571862 , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.24783087, 0.        , 0.17910388, ..., 0.00819932,\n",
       "          0.77976018, 0.        ],\n",
       "         [0.60840362, 0.        , 0.        , ..., 0.        ,\n",
       "          0.98788977, 0.        ],\n",
       "         [0.35977066, 0.        , 0.        , ..., 0.        ,\n",
       "          1.08075106, 0.        ],\n",
       "         ...,\n",
       "         [0.47616649, 0.        , 0.        , ..., 0.        ,\n",
       "          0.93735796, 0.        ],\n",
       "         [0.51126671, 0.        , 0.        , ..., 0.        ,\n",
       "          1.03437889, 0.        ],\n",
       "         [0.81270564, 0.        , 0.        , ..., 0.        ,\n",
       "          0.69630051, 0.        ]],\n",
       "\n",
       "        [[0.45768824, 0.        , 0.        , ..., 0.        ,\n",
       "          0.74390739, 0.        ],\n",
       "         [0.63775712, 0.        , 0.        , ..., 0.        ,\n",
       "          0.78291696, 0.        ],\n",
       "         [0.30780149, 0.        , 1.07862496, ..., 0.        ,\n",
       "          0.47447616, 0.        ],\n",
       "         ...,\n",
       "         [0.61711836, 0.        , 0.46756217, ..., 0.        ,\n",
       "          1.15586734, 0.        ],\n",
       "         [0.63516855, 0.        , 0.        , ..., 0.        ,\n",
       "          1.15119815, 0.        ],\n",
       "         [0.84615719, 0.        , 0.        , ..., 0.        ,\n",
       "          0.67780823, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.8761068 , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.77610368, 0.        ],\n",
       "         [0.16806437, 0.        , 0.64615196, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.1428048 , 0.        , 0.35540348, ..., 0.        ,\n",
       "          0.76034123, 0.        ],\n",
       "         [0.        , 0.        , 0.52707613, ..., 0.        ,\n",
       "          0.6798479 , 0.        ],\n",
       "         [0.        , 0.        , 0.15767884, ..., 0.        ,\n",
       "          0.47838008, 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.26138601, 0.        , 0.        , ..., 0.        ,\n",
       "          0.51263565, 0.        ],\n",
       "         [0.77460539, 0.        , 0.52325279, ..., 0.        ,\n",
       "          0.24300447, 0.        ],\n",
       "         [1.03216648, 0.        , 0.75543141, ..., 0.        ,\n",
       "          0.00653607, 0.        ],\n",
       "         ...,\n",
       "         [1.44265878, 0.        , 0.27564678, ..., 0.        ,\n",
       "          0.96461475, 0.        ],\n",
       "         [0.92718154, 0.        , 0.10412565, ..., 0.        ,\n",
       "          1.24312329, 0.        ],\n",
       "         [0.98219788, 0.        , 0.30129331, ..., 0.        ,\n",
       "          1.32267416, 0.        ]],\n",
       "\n",
       "        [[0.06162368, 0.        , 0.        , ..., 0.        ,\n",
       "          0.90249312, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.84242773, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.35500225,\n",
       "          1.03745246, 0.        ],\n",
       "         ...,\n",
       "         [0.40948987, 0.        , 0.12457001, ..., 0.        ,\n",
       "          1.41843724, 0.        ],\n",
       "         [0.40398365, 0.        , 0.30985025, ..., 0.        ,\n",
       "          1.33558869, 0.        ],\n",
       "         [0.54411983, 0.        , 0.50785202, ..., 0.        ,\n",
       "          0.83510071, 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.02054155, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.01041734, 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.82854688, 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          1.35846806, 0.        ],\n",
       "         [0.        , 0.        , 0.36851197, ..., 0.        ,\n",
       "          1.40417242, 0.        ],\n",
       "         [0.12621507, 0.        , 0.13068646, ..., 0.04773771,\n",
       "          0.82294261, 0.        ]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 3,078\n",
      "Trainable params: 3,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(7,7,512)))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.7992 - acc: 0.1862 - val_loss: 1.7096 - val_acc: 0.1969\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.70958, saving model to model-001-0.186170-0.196850.h5\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6927 - acc: 0.2553 - val_loss: 1.6419 - val_acc: 0.3228\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.70958 to 1.64189, saving model to model-002-0.255319-0.322835.h5\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6403 - acc: 0.3245 - val_loss: 1.6013 - val_acc: 0.4173\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.64189 to 1.60135, saving model to model-003-0.324468-0.417323.h5\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5981 - acc: 0.4574 - val_loss: 1.5617 - val_acc: 0.5276\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.60135 to 1.56171, saving model to model-004-0.457447-0.527559.h5\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5563 - acc: 0.5585 - val_loss: 1.5213 - val_acc: 0.6063\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.56171 to 1.52126, saving model to model-005-0.558511-0.606299.h5\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5126 - acc: 0.6436 - val_loss: 1.4829 - val_acc: 0.6378\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.52126 to 1.48292, saving model to model-006-0.643617-0.637795.h5\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.4727 - acc: 0.6809 - val_loss: 1.4458 - val_acc: 0.7165\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.48292 to 1.44579, saving model to model-007-0.680851-0.716535.h5\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4335 - acc: 0.7287 - val_loss: 1.4096 - val_acc: 0.7559\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.44579 to 1.40960, saving model to model-008-0.728723-0.755906.h5\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3958 - acc: 0.7340 - val_loss: 1.3731 - val_acc: 0.7638\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.40960 to 1.37306, saving model to model-009-0.734043-0.763780.h5\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3595 - acc: 0.7500 - val_loss: 1.3393 - val_acc: 0.7244\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.37306 to 1.33934, saving model to model-010-0.750000-0.724409.h5\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3227 - acc: 0.7819 - val_loss: 1.3059 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.33934 to 1.30589, saving model to model-011-0.781915-0.779528.h5\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2899 - acc: 0.7979 - val_loss: 1.2749 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.30589 to 1.27488, saving model to model-012-0.797872-0.811024.h5\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2543 - acc: 0.8191 - val_loss: 1.2443 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.27488 to 1.24427, saving model to model-013-0.819149-0.811024.h5\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2223 - acc: 0.8351 - val_loss: 1.2141 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.24427 to 1.21409, saving model to model-014-0.835106-0.811024.h5\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1939 - acc: 0.8351 - val_loss: 1.1857 - val_acc: 0.8031\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.21409 to 1.18574, saving model to model-015-0.835106-0.803150.h5\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1632 - acc: 0.8457 - val_loss: 1.1584 - val_acc: 0.8346\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.18574 to 1.15843, saving model to model-016-0.845745-0.834646.h5\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1355 - acc: 0.8511 - val_loss: 1.1329 - val_acc: 0.8268\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.15843 to 1.13291, saving model to model-017-0.851064-0.826772.h5\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1062 - acc: 0.8564 - val_loss: 1.1070 - val_acc: 0.8425\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.13291 to 1.10696, saving model to model-018-0.856383-0.842520.h5\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0805 - acc: 0.8670 - val_loss: 1.0830 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.10696 to 1.08295, saving model to model-019-0.867021-0.858268.h5\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0539 - acc: 0.8670 - val_loss: 1.0591 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.08295 to 1.05910, saving model to model-020-0.867021-0.858268.h5\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0293 - acc: 0.8617 - val_loss: 1.0367 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.05910 to 1.03666, saving model to model-021-0.861702-0.858268.h5\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0070 - acc: 0.8670 - val_loss: 1.0151 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.03666 to 1.01505, saving model to model-022-0.867021-0.858268.h5\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9827 - acc: 0.8936 - val_loss: 0.9944 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.01505 to 0.99443, saving model to model-023-0.893617-0.866142.h5\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9605 - acc: 0.8883 - val_loss: 0.9749 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.99443 to 0.97488, saving model to model-024-0.888298-0.850394.h5\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9401 - acc: 0.8883 - val_loss: 0.9560 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.97488 to 0.95597, saving model to model-025-0.888298-0.866142.h5\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9198 - acc: 0.8989 - val_loss: 0.9374 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.95597 to 0.93739, saving model to model-026-0.898936-0.866142.h5\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9020 - acc: 0.8989 - val_loss: 0.9195 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.93739 to 0.91950, saving model to model-027-0.898936-0.874016.h5\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8825 - acc: 0.8989 - val_loss: 0.9021 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.91950 to 0.90211, saving model to model-028-0.898936-0.874016.h5\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8637 - acc: 0.9043 - val_loss: 0.8860 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.90211 to 0.88598, saving model to model-029-0.904255-0.874016.h5\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8452 - acc: 0.9043 - val_loss: 0.8700 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.88598 to 0.86995, saving model to model-030-0.904255-0.874016.h5\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8292 - acc: 0.9043 - val_loss: 0.8551 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.86995 to 0.85513, saving model to model-031-0.904255-0.881890.h5\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8118 - acc: 0.9043 - val_loss: 0.8403 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.85513 to 0.84025, saving model to model-032-0.904255-0.874016.h5\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7990 - acc: 0.9043 - val_loss: 0.8264 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.84025 to 0.82643, saving model to model-033-0.904255-0.881890.h5\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7811 - acc: 0.9096 - val_loss: 0.8121 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.82643 to 0.81205, saving model to model-034-0.909574-0.881890.h5\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7677 - acc: 0.9043 - val_loss: 0.7992 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.81205 to 0.79922, saving model to model-035-0.904255-0.881890.h5\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7523 - acc: 0.9043 - val_loss: 0.7860 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.79922 to 0.78596, saving model to model-036-0.904255-0.881890.h5\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7400 - acc: 0.9096 - val_loss: 0.7738 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.78596 to 0.77384, saving model to model-037-0.909574-0.897638.h5\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7259 - acc: 0.9096 - val_loss: 0.7622 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.77384 to 0.76220, saving model to model-038-0.909574-0.897638.h5\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7125 - acc: 0.9096 - val_loss: 0.7511 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.76220 to 0.75113, saving model to model-039-0.909574-0.881890.h5\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6997 - acc: 0.9096 - val_loss: 0.7404 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.75113 to 0.74036, saving model to model-040-0.909574-0.881890.h5\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6880 - acc: 0.9149 - val_loss: 0.7290 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.74036 to 0.72905, saving model to model-041-0.914894-0.897638.h5\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6757 - acc: 0.9149 - val_loss: 0.7190 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.72905 to 0.71899, saving model to model-042-0.914894-0.889764.h5\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6661 - acc: 0.9149 - val_loss: 0.7092 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.71899 to 0.70925, saving model to model-043-0.914894-0.889764.h5\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6534 - acc: 0.9149 - val_loss: 0.6993 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.70925 to 0.69928, saving model to model-044-0.914894-0.897638.h5\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6430 - acc: 0.9255 - val_loss: 0.6902 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.69928 to 0.69022, saving model to model-045-0.925532-0.897638.h5\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6328 - acc: 0.9255 - val_loss: 0.6812 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.69022 to 0.68118, saving model to model-046-0.925532-0.897638.h5\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6217 - acc: 0.9362 - val_loss: 0.6723 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.68118 to 0.67232, saving model to model-047-0.936170-0.897638.h5\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6134 - acc: 0.9309 - val_loss: 0.6636 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.67232 to 0.66360, saving model to model-048-0.930851-0.889764.h5\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6028 - acc: 0.9362 - val_loss: 0.6554 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.66360 to 0.65541, saving model to model-049-0.936170-0.897638.h5\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5953 - acc: 0.9255 - val_loss: 0.6481 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.65541 to 0.64807, saving model to model-050-0.925532-0.897638.h5\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5846 - acc: 0.9362 - val_loss: 0.6404 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.64807 to 0.64044, saving model to model-051-0.936170-0.897638.h5\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5758 - acc: 0.9362 - val_loss: 0.6329 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.64044 to 0.63291, saving model to model-052-0.936170-0.897638.h5\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5686 - acc: 0.9415 - val_loss: 0.6252 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.63291 to 0.62519, saving model to model-053-0.941489-0.897638.h5\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5596 - acc: 0.9468 - val_loss: 0.6178 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.62519 to 0.61779, saving model to model-054-0.946809-0.897638.h5\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5521 - acc: 0.9468 - val_loss: 0.6107 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.61779 to 0.61068, saving model to model-055-0.946809-0.897638.h5\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5435 - acc: 0.9415 - val_loss: 0.6043 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.61068 to 0.60432, saving model to model-056-0.941489-0.905512.h5\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5362 - acc: 0.9468 - val_loss: 0.5978 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.60432 to 0.59785, saving model to model-057-0.946809-0.897638.h5\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5282 - acc: 0.9521 - val_loss: 0.5913 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.59785 to 0.59134, saving model to model-058-0.952128-0.897638.h5\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5221 - acc: 0.9521 - val_loss: 0.5861 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.59134 to 0.58615, saving model to model-059-0.952128-0.905512.h5\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5146 - acc: 0.9574 - val_loss: 0.5797 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.58615 to 0.57975, saving model to model-060-0.957447-0.897638.h5\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5072 - acc: 0.9521 - val_loss: 0.5739 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.57975 to 0.57392, saving model to model-061-0.952128-0.905512.h5\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5005 - acc: 0.9521 - val_loss: 0.5674 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.57392 to 0.56743, saving model to model-062-0.952128-0.905512.h5\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4934 - acc: 0.9521 - val_loss: 0.5619 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.56743 to 0.56194, saving model to model-063-0.952128-0.905512.h5\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4871 - acc: 0.9574 - val_loss: 0.5571 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.56194 to 0.55707, saving model to model-064-0.957447-0.905512.h5\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4814 - acc: 0.9628 - val_loss: 0.5516 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.55707 to 0.55161, saving model to model-065-0.962766-0.905512.h5\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4755 - acc: 0.9574 - val_loss: 0.5468 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.55161 to 0.54679, saving model to model-066-0.957447-0.905512.h5\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4696 - acc: 0.9574 - val_loss: 0.5418 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.54679 to 0.54177, saving model to model-067-0.957447-0.905512.h5\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4626 - acc: 0.9574 - val_loss: 0.5369 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.54177 to 0.53686, saving model to model-068-0.957447-0.905512.h5\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4576 - acc: 0.9628 - val_loss: 0.5319 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.53686 to 0.53194, saving model to model-069-0.962766-0.905512.h5\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4524 - acc: 0.9628 - val_loss: 0.5273 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.53194 to 0.52729, saving model to model-070-0.962766-0.905512.h5\n",
      "Epoch 71/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4463 - acc: 0.9628 - val_loss: 0.5231 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.52729 to 0.52309, saving model to model-071-0.962766-0.905512.h5\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4411 - acc: 0.9628 - val_loss: 0.5192 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.52309 to 0.51923, saving model to model-072-0.962766-0.905512.h5\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4361 - acc: 0.9628 - val_loss: 0.5145 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.51923 to 0.51451, saving model to model-073-0.962766-0.913386.h5\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4302 - acc: 0.9628 - val_loss: 0.5098 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.51451 to 0.50977, saving model to model-074-0.962766-0.905512.h5\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4255 - acc: 0.9628 - val_loss: 0.5054 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.50977 to 0.50537, saving model to model-075-0.962766-0.905512.h5\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4206 - acc: 0.9628 - val_loss: 0.5011 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.50537 to 0.50110, saving model to model-076-0.962766-0.905512.h5\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4157 - acc: 0.9681 - val_loss: 0.4972 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.50110 to 0.49720, saving model to model-077-0.968085-0.913386.h5\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4107 - acc: 0.9681 - val_loss: 0.4938 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.49720 to 0.49375, saving model to model-078-0.968085-0.905512.h5\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4070 - acc: 0.9681 - val_loss: 0.4910 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.49375 to 0.49104, saving model to model-079-0.968085-0.897638.h5\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4014 - acc: 0.9681 - val_loss: 0.4867 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.49104 to 0.48672, saving model to model-080-0.968085-0.905512.h5\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3971 - acc: 0.9681 - val_loss: 0.4833 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.48672 to 0.48334, saving model to model-081-0.968085-0.913386.h5\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3929 - acc: 0.9734 - val_loss: 0.4790 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.48334 to 0.47897, saving model to model-082-0.973404-0.905512.h5\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3884 - acc: 0.9734 - val_loss: 0.4760 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.47897 to 0.47601, saving model to model-083-0.973404-0.905512.h5\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3841 - acc: 0.9734 - val_loss: 0.4728 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.47601 to 0.47277, saving model to model-084-0.973404-0.913386.h5\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3809 - acc: 0.9734 - val_loss: 0.4687 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.47277 to 0.46867, saving model to model-085-0.973404-0.913386.h5\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3765 - acc: 0.9734 - val_loss: 0.4656 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.46867 to 0.46560, saving model to model-086-0.973404-0.913386.h5\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3716 - acc: 0.9734 - val_loss: 0.4628 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.46560 to 0.46279, saving model to model-087-0.973404-0.913386.h5\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3680 - acc: 0.9734 - val_loss: 0.4595 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.46279 to 0.45946, saving model to model-088-0.973404-0.905512.h5\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3643 - acc: 0.9734 - val_loss: 0.4565 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.45946 to 0.45649, saving model to model-089-0.973404-0.913386.h5\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3603 - acc: 0.9734 - val_loss: 0.4528 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.45649 to 0.45276, saving model to model-090-0.973404-0.913386.h5\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3567 - acc: 0.9734 - val_loss: 0.4504 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.45276 to 0.45043, saving model to model-091-0.973404-0.921260.h5\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3530 - acc: 0.9734 - val_loss: 0.4476 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.45043 to 0.44762, saving model to model-092-0.973404-0.913386.h5\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3493 - acc: 0.9734 - val_loss: 0.4444 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.44762 to 0.44437, saving model to model-093-0.973404-0.913386.h5\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3458 - acc: 0.9734 - val_loss: 0.4417 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.44437 to 0.44170, saving model to model-094-0.973404-0.913386.h5\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3431 - acc: 0.9734 - val_loss: 0.4392 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.44170 to 0.43918, saving model to model-095-0.973404-0.921260.h5\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3385 - acc: 0.9787 - val_loss: 0.4364 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.43918 to 0.43641, saving model to model-096-0.978723-0.921260.h5\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3357 - acc: 0.9734 - val_loss: 0.4336 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.43641 to 0.43358, saving model to model-097-0.973404-0.913386.h5\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3325 - acc: 0.9734 - val_loss: 0.4315 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.43358 to 0.43151, saving model to model-098-0.973404-0.913386.h5\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3289 - acc: 0.9734 - val_loss: 0.4291 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.43151 to 0.42906, saving model to model-099-0.973404-0.913386.h5\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3255 - acc: 0.9787 - val_loss: 0.4258 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.42906 to 0.42576, saving model to model-100-0.978723-0.921260.h5\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3224 - acc: 0.9840 - val_loss: 0.4233 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.42576 to 0.42327, saving model to model-101-0.984043-0.921260.h5\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3190 - acc: 0.9840 - val_loss: 0.4211 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.42327 to 0.42111, saving model to model-102-0.984043-0.921260.h5\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3161 - acc: 0.9894 - val_loss: 0.4188 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.42111 to 0.41885, saving model to model-103-0.989362-0.921260.h5\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3133 - acc: 0.9840 - val_loss: 0.4164 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.41885 to 0.41640, saving model to model-104-0.984043-0.921260.h5\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3109 - acc: 0.9840 - val_loss: 0.4151 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.41640 to 0.41513, saving model to model-105-0.984043-0.913386.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3072 - acc: 0.9894 - val_loss: 0.4123 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.41513 to 0.41225, saving model to model-106-0.989362-0.921260.h5\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3047 - acc: 0.9894 - val_loss: 0.4101 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.41225 to 0.41011, saving model to model-107-0.989362-0.913386.h5\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3016 - acc: 0.9894 - val_loss: 0.4076 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.41011 to 0.40763, saving model to model-108-0.989362-0.921260.h5\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2985 - acc: 0.9894 - val_loss: 0.4052 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.40763 to 0.40521, saving model to model-109-0.989362-0.921260.h5\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2959 - acc: 0.9894 - val_loss: 0.4028 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.40521 to 0.40276, saving model to model-110-0.989362-0.921260.h5\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2934 - acc: 0.9894 - val_loss: 0.4006 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.40276 to 0.40064, saving model to model-111-0.989362-0.921260.h5\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2904 - acc: 0.9894 - val_loss: 0.3989 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.40064 to 0.39893, saving model to model-112-0.989362-0.921260.h5\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2880 - acc: 0.9894 - val_loss: 0.3972 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.39893 to 0.39719, saving model to model-113-0.989362-0.921260.h5\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2851 - acc: 0.9894 - val_loss: 0.3949 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.39719 to 0.39487, saving model to model-114-0.989362-0.921260.h5\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2826 - acc: 0.9894 - val_loss: 0.3933 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.39487 to 0.39330, saving model to model-115-0.989362-0.921260.h5\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2803 - acc: 0.9894 - val_loss: 0.3910 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.39330 to 0.39104, saving model to model-116-0.989362-0.921260.h5\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2778 - acc: 0.9894 - val_loss: 0.3891 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.39104 to 0.38912, saving model to model-117-0.989362-0.921260.h5\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2755 - acc: 0.9894 - val_loss: 0.3872 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.38912 to 0.38722, saving model to model-118-0.989362-0.921260.h5\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2729 - acc: 0.9894 - val_loss: 0.3857 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.38722 to 0.38569, saving model to model-119-0.989362-0.921260.h5\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2704 - acc: 0.9894 - val_loss: 0.3838 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.38569 to 0.38385, saving model to model-120-0.989362-0.921260.h5\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2678 - acc: 0.9894 - val_loss: 0.3822 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.38385 to 0.38217, saving model to model-121-0.989362-0.921260.h5\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2656 - acc: 0.9894 - val_loss: 0.3808 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.38217 to 0.38075, saving model to model-122-0.989362-0.921260.h5\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2640 - acc: 0.9894 - val_loss: 0.3792 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.38075 to 0.37924, saving model to model-123-0.989362-0.921260.h5\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2612 - acc: 0.9894 - val_loss: 0.3767 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.37924 to 0.37670, saving model to model-124-0.989362-0.921260.h5\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2594 - acc: 0.9894 - val_loss: 0.3745 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.37670 to 0.37448, saving model to model-125-0.989362-0.921260.h5\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2569 - acc: 0.9894 - val_loss: 0.3733 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.37448 to 0.37334, saving model to model-126-0.989362-0.921260.h5\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2545 - acc: 0.9894 - val_loss: 0.3716 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.37334 to 0.37160, saving model to model-127-0.989362-0.921260.h5\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2525 - acc: 0.9894 - val_loss: 0.3697 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.37160 to 0.36968, saving model to model-128-0.989362-0.921260.h5\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2502 - acc: 0.9894 - val_loss: 0.3684 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.36968 to 0.36835, saving model to model-129-0.989362-0.921260.h5\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2485 - acc: 0.9894 - val_loss: 0.3675 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.36835 to 0.36749, saving model to model-130-0.989362-0.921260.h5\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2460 - acc: 0.9894 - val_loss: 0.3656 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.36749 to 0.36559, saving model to model-131-0.989362-0.921260.h5\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2441 - acc: 0.9894 - val_loss: 0.3634 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.36559 to 0.36343, saving model to model-132-0.989362-0.921260.h5\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2419 - acc: 0.9894 - val_loss: 0.3622 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.36343 to 0.36223, saving model to model-133-0.989362-0.921260.h5\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2400 - acc: 0.9894 - val_loss: 0.3607 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.36223 to 0.36074, saving model to model-134-0.989362-0.929134.h5\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2388 - acc: 0.9894 - val_loss: 0.3591 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.36074 to 0.35908, saving model to model-135-0.989362-0.921260.h5\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2367 - acc: 0.9894 - val_loss: 0.3579 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.35908 to 0.35785, saving model to model-136-0.989362-0.921260.h5\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2346 - acc: 0.9894 - val_loss: 0.3567 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.35785 to 0.35671, saving model to model-137-0.989362-0.929134.h5\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2323 - acc: 0.9894 - val_loss: 0.3553 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.35671 to 0.35535, saving model to model-138-0.989362-0.929134.h5\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2305 - acc: 0.9894 - val_loss: 0.3540 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.35535 to 0.35401, saving model to model-139-0.989362-0.929134.h5\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2288 - acc: 0.9894 - val_loss: 0.3519 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.35401 to 0.35190, saving model to model-140-0.989362-0.921260.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2267 - acc: 0.9894 - val_loss: 0.3505 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.35190 to 0.35048, saving model to model-141-0.989362-0.929134.h5\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2253 - acc: 0.9894 - val_loss: 0.3493 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.35048 to 0.34933, saving model to model-142-0.989362-0.929134.h5\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2237 - acc: 0.9894 - val_loss: 0.3481 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.34933 to 0.34811, saving model to model-143-0.989362-0.929134.h5\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2216 - acc: 0.9894 - val_loss: 0.3470 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.34811 to 0.34695, saving model to model-144-0.989362-0.929134.h5\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2201 - acc: 0.9894 - val_loss: 0.3461 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.34695 to 0.34611, saving model to model-145-0.989362-0.929134.h5\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2180 - acc: 0.9894 - val_loss: 0.3447 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.34611 to 0.34474, saving model to model-146-0.989362-0.929134.h5\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2170 - acc: 0.9894 - val_loss: 0.3431 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.34474 to 0.34307, saving model to model-147-0.989362-0.929134.h5\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2144 - acc: 0.9894 - val_loss: 0.3417 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.34307 to 0.34173, saving model to model-148-0.989362-0.929134.h5\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2137 - acc: 0.9894 - val_loss: 0.3401 - val_acc: 0.9370\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.34173 to 0.34006, saving model to model-149-0.989362-0.937008.h5\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2114 - acc: 0.9894 - val_loss: 0.3394 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.34006 to 0.33936, saving model to model-150-0.989362-0.929134.h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "\n",
    "# Compile model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(1, len(acc)+1)\n",
    "\n",
    "# plt.plot(epochs, acc, 'g', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def prediction(img_path):\n",
    "    org_img = image.load_img(img_path)\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    img_tensor = image.img_to_array(img)  # Image data encoded as integers in the 0255 range\n",
    "    img_tensor /= 255.  # Normalize to [0,1] for plt.imshow application\n",
    "    plt.imshow(org_img)                           \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Extract features\n",
    "    features = model_base.predict(img_tensor.reshape(1,img_width, img_height, 3))\n",
    "\n",
    "    # Make prediction\n",
    "    try:\n",
    "        prediction = model.predict(features)\n",
    "    except:\n",
    "        prediction = model.predict(features.reshape(1, 7*7*512))\n",
    "        \n",
    "    classes = [\"ant\", \"budhha\", \"dolphin\", \"elephant\", \"flamingo\", \"rooster\"]\n",
    "    print(\"This Image is of a... \"+str(classes[np.argmax(np.array(prediction[0]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_width' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-69bba677b1ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpred_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-fb46478ae98e>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0morg_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Image data encoded as integers in the 0255 range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg_tensor\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.\u001b[0m  \u001b[0;31m# Normalize to [0,1] for plt.imshow application\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_width' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "pred_dir = []\n",
    "for d in os.listdir(\"dataset/\"):\n",
    "    for f in os.listdir(\"dataset/\"+str(d)):\n",
    "        pred_dir.append(str(d)+\"/\"+f)\n",
    "pred_files = random.sample(pred_dir,20)\n",
    "for f in pred_files:\n",
    "    prediction(\"dataset/\"+f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
